# Default configuration for transformer model training
model_name: "transformer_default"

# Data parameters
data_dir: "../selected_h5/"
num_files: 50
max_cells: 40
min_cells: 3
cell_selection_feature: "Cell_e"
use_spatial_features: false

# Cell filtering parameters
use_cell_track_matching: true
require_valid_cells: true
additional_cell_filters: {}

# Data split parameters
test_size: 0.3
val_split: 0.33333  # 1/3
random_state: 42

# Model architecture parameters
d_model: 128
num_heads: 8
dff: 256
num_transformer_blocks: 3
dropout_rate: 0.1

# Dense layer parameters
vertex_dense_units: 64
final_dense_units: [256, 128, 64]
final_dropout_rates: [0.3, 0.2, 0.1]
use_batch_norm: true

# Training parameters
batch_size: 64
epochs: 50
learning_rate: 0.0001
lr_reduction_factor: 0.5
early_stopping_patience: 15
lr_patience: 5
min_lr: 0.0000001

# Model save parameters
models_base_dir: "models"

# Feature definitions
spatial_features: ["Cell_x", "Cell_y", "Cell_z"]
vertex_spatial_features: ["HSvertex_reco_x", "HSvertex_reco_y", "HSvertex_reco_z"]
all_cell_features:
  - "Cell_x"
  - "Cell_y" 
  - "Cell_z"
  - "Cell_eta"
  - "Cell_phi"
  - "Cell_Barrel"
  - "Cell_layer"
  - "Cell_time_TOF_corrected"
  - "Cell_e"
  - "Cell_significance"
  - "matched_track_pt"
  - "matched_track_deltaR"
skip_normalization: ["Cell_time_TOF_corrected", "Cell_Barrel", "Cell_layer"]